\section{Submitted Work}
\label{sec:done}

    During my first year as a DPhil student at Oxford we developed the Hierarchical Attentive Recurrent Tracking (HART) framework. It was submitted to NIPS 2017. This RNN-based model learns to track objects in videos by focusing on small image regions, usually not much bigger than the tracked objects. It does so by using a differentiable attention mechanism, which can effectively crop a part of the image, thereby quickly removing irrelevant parts of the input.
    Upscaling HART to a challenging real-world dataset proved difficult, as end-to-end training on a randomly initialised neural network was very unstable and converged to poor results. To address this issue, I resorted to transfer learning and used AlexNet \citep{Krizhevsky2012} as a feature extractor, which has stabilised the training and improved performance (\emph{cf.} section 5.2. in the paper).
    
    Feature extractors pre-trained on static image analysis tasks are often used for processing video sequences (see \eg \cite{Ning2016a}). This approach, while effective, has little justification in neuroscience. In contrary, there is a growing body of evidence indicating the importance of temporal connections in the human visual cortex \citep{Ungerleider2000}, which suggests that the temporal integration of information is vital for building up high resolution representation of the world.   
    
    Modern single-object-tracking approaches are based on either metric learning or bounding box regression (\cite{Bertinetto2016} and \cite{Held2016}, respectively). Not only do they need to rely on heuristics (non-differentiable image cropping, explicit scale search) to achieve computational efficiency and accuracy, but they are also fully dependent on a single error signal for learning.
    HART, on the other hand, exploits the model structure to make more efficient use of the error signal. It uses the ground-truth bounding boxes to derive three related but distinct learning signals, one of each for the model parts. One of them, the object masks for foreground-background segmentation of extracted attention glimpses, can be seen as self-supervision.
    It serves different purposes: (a) it forces the model to store object appearance information in the hidden state, (b) it encourages better spatial attention prediction, as computing the object mask is easier (lower relative penalty for any mistakes) if the object covers a bigger part of the attention glimpse and (c) since the ground-truth object mask is computed on the fly, it serves as data-augmentation, in the sense that the errors and the learning signal is dependent on the model parameters and is different in every iteration of training even if the input data is the same.
    Despite being trained under full supervision, HART was a test bench I used to learn about learning in the presence of temporal dependencies and to experiment  with different structures of the objective function so as to maximise learning from a limited amount of data.
    
    
   \includepdf[pages=-, pagecommand={}]{HART_final.pdf}