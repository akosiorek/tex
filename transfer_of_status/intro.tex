\section{Introduction}    
    
%    We spend our lives roaming through the space-time continuum and our brains have evolved to use omnipresent temporal dependencies. They determine the evolution of the outside world, but they also, or maybe because of that, facilitate learning in humans. Even when time itself is not important, temporally-ordered sequence of informative events can introduce context and condition further information processing. Time dependencies permeate our existence to the extent that it is hard to find examples of reasoning not involving them. And yet, the majority of machine learning (ML) algorithms either do not use temporal dependencies at all or do so in a very limited sense. 
%    With no reliance on temporal dependencies, supervised ML algorithms are forced to heavily depend on expensive human-labelled data, while accounting for all redundancies therein. I am going to argue that explicit time-series modelling and interaction with the environment are enough to create a powerful signal for self-supervised learning. The resulting feedback loop eliminates the need for huge human-tagged datasets, while improving performance of the existing approaches at the same time.
%    
%    To this end, I am going to explore the use of Bayesian neural networks for time-series modelling. While my focus is on unsupervised or rather self-supervised learning, I will also explore the connection between learning and interacting with the environment. Specifically, I will argue that structured time-series prediction can lead to learning rich neural representations of sensory inputs. By following the probabilistic approach, it is possible to remove redundancies from the data and model attention mechanisms similar to those present in the human brain. I will also argue that enforcing particular model structure is equivalent to introducing prior information into the model, thereby constraining the learning problem and making it easier to learn certain properties of the dataset. In doing so, I will build on the recent advances in variational inference and construct a generative framework for unsupervised single object tracking in videos. Finally, I will use the learned model for model-based reinforcement learning (RL), with the purpose of improving sample efficiency of RL on one hand, and boosting the learning speed of the perception module by interaction with the environment on the other. 
%
%    My work as a DPhil student at Oxford started with the problem of single object tracking in videos, which resulted in a NIPS submission \citep{Kosiorek2017}.    
%    This project gave me an opportunity to explore learning in the presence of temporal dependencies and to explore the concept of self-supervision: how to make the system learn better without using any additional external (\eg ground-truth) information? 
%    The rest of this paper is structured as follows:
%    \Cref{sec:lit} covers prior work related to the areas in question.
%    I summarise the tasks of sequence prediction, predictive coding, variants of unsupervised learning and present a number of relevant approaches.
%    In the \cref{sec:done}, I describe my work on object tracking and how it ties with my interests and the planned future work on structured unsupervised learning for videos, predictive coding and model-based reinforcement learning.
%    \Cref{sec:proposal} describes my future research plans, related risks and expected outcomes.
%    \Cref{sec:conclusions} concludes this work. 
    
    Sequence prediction is a powerful framework for unsupervised learning. With the abundance of sequential real-world data available, it is possible to train large and highly-complex models for the next time-step prediction. While temporal dependencies facilitate learning in humans, the majority of machine learning (ML) algorithms either do not use them or do so in a very limited sense. Temporal dependencies determine the evolution of the world, and therefore it is possible that models trained for sequence prediction can learn intuitive physics and that they might be useful in model-based reinforcement learning.
    
    While sequence predictors achieve some success, they generally do not provide interpretable representations that could be easily used for downstream tasks, nor do they use any prior information about the problem. Recent advances in variational inference and neural networks allow building efficient generative models of high-dimensional data. They do so by specifying the probability distribution of observed data in terms of (typically low-dimensional) auxiliary latent variables. On one hand, the latent variables explain the observations and can be useful in downstream tasks. On the other hand, the stochasticity of this approach affords better regularisation and uncertainty estimates. The problem of including prior information has not been addressed, however.
    
    All work performed under this thesis will aim at utilising prior information in generative models of time-series and exploiting these models in the context of model-based reinforcement learning. We will argue that prior information can be introduced by structuring the model appropriately, thereby factorising latent variables and enforcing their \emph{specific} semantic meaning. In the process, we will construct a generative model of moving objects, capable of describing the scene with variable-length latent representation. This model will make it possible to learn intuitive physics and simulate future motion and appearance changes of visible objects. Finally, we will use this model in the Dyna \citep{Sutton1991} framework, with the goal of improving sample-efficiency of model-free reinforcement learning algorithms.
    
    The rest of this paper is structured as follows.
    \Cref{sec:lit} covers prior work related to the areas in question.
    I summarise the task of sequence prediction, describe some variants of unsupervised learning and investigate how model structure helps to learn abstract concepts from data.
    In \cref{sec:done}, I describe our work on object tracking and how it ties with my interests and the planned future work on structured unsupervised learning for videos and model-based reinforcement learning.
    \Cref{sec:proposal} details my future research plans, related risks and expected outcomes.
    \Cref{sec:conclusions} concludes this work.