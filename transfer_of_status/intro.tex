\section{Introduction}    
    
    We spend our lives roaming through the space-time continuum and our brains have evolved to use omnipresent temporal dependencies. They determine the evolution of the outside world, but they also, or maybe because of that, facilitate learning in humans. Even when time itself is not important, temporally-ordered sequence of informative events can introduce context and condition further information processing. Time dependencies permeate our existence to the extent that it is hard to find examples of reasoning not involving them. And yet, the majority of machine learning (ML) algorithms either do not use temporal dependencies at all or do so in a very limited sense. 
    With no reliance on temporal dependencies, supervised ML algorithms are forced to heavily depend on expensive human-labelled data, while accounting for all redundancies therein. I am going to argue that explicit time-series modelling and interaction with the environment are enough to create a powerful signal for self-supervised learning. The resulting feedback loop eliminates the need for huge human-tagged datasets, while improving performance of the existing approaches at the same time.
    
    To this end, I am going to explore the use of probabilistic neural networks for time-series modelling. While my focus is on unsupervised or rather self-supervised learning, I will also explore the connection between learning and interacting with the environment. Specifically, I will argue that structured time-series prediction can lead to learning rich neural representations of sensory inputs. By following the probabilistic approach, it is possible to remove redundancies from the data and model attention mechanisms similar to those present in the human brain. I will also argue that enforcing particular model structure is equivalent to introducing prior information into the model, thereby constraining the learning problem and making it easier to learn certain properties of the dataset. In doing so, I will build on the recent advances in variational inference and construct a generative framework for unsupervised single object tracking in videos. Finally, I will use the learned model for model-based reinforcement learning (RL), with the purpose of improving sample efficiency of RL on one hand, and boosting the learning speed of the perception module by interaction with the environment on the other. 

    My work as a DPhil student at Oxford started with the problem of single object tracking in videos, which resulted in a NIPS submission \citep{Kosiorek2017}.    
    This project gave me an opportunity to explore learning in the presence of temporal dependencies and to explore the concept of self-supervision: how to make the system learn better without using any additional external (\eg ground-truth) information? 
    The rest of this paper is structured as follows:
    \Cref{sec:lit} covers prior work related to the areas in question.
    Specifically, I summarise the tasks of sequence prediction, predictive coding, variants of unsupervised learning and present a number of relevant approaches.
    In the \cref{sec:done}, I describe the work on object tracking and how it ties with my interests and the planned future work on structured unsupervised learning for videos, predictive coding and model-based reinforcement learning.
    \Cref{sec:proposal} describes my future research plans, related risks and expected outcomes.
    \Cref{sec:conclusions} concludes this work. 