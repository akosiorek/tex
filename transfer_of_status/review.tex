\section{Related Work}
\label{sec:lit}

%    Things to write about:
%    \begin{itemize}
%        \item Sequence prediction: text, motion, videos
%        \item Predictive Coding
%        \item Semi-supervised learning: learning by association and ladder networks
%        \item behaviour learning by RL: maze navigation, locomotion patters
%        \item unsupervised learning: AIR
%    \end{itemize}


    We start the discussion of related works with the Dyna framework and describe the role of its components. We then proceed to the tasks of unsupervised learning and sequence modelling, which are important for incorporating prior information and learning non-stationary models of environment dynamics, respectively, which we hope can be used to pre-train a model of the environment to be used within Dyna. Finally, we touch on how \emph{appropriate} structuring of the model can aid representation learning, thereby improving the quality of the environment model.
    
    \subsection{Generative Modelling for Reinforcement Learning}
        Model-free RL is data hungry and improving sample efficiency of model-free methods is a long-standing research problem. \cite{Sutton1991} introduced the Dyna architecture, which uses and jointly trains a model-free parametric policy and a generative model of the environment. The former allows efficient inference and optimal performance, the latter reduces number of samples required from the environment by providing model-based simulations.
        Despite the theoretical advantages, it has been very difficult in practice to implement Dyna for anything but the simplest RL problems due to instabilities introduced by the learning of non-linear function approximators.
        \cite{Gu2016} managed to use use the Dyna framework with a non-linear policy network, but showed that using neural networks for the environment model leads to lower performance than using linear approximators due to slow learning of the former. 
        \cite{Nagabandi2017} has overcome this issue by using a mid-sized neural network as the environment model and pre-training it without supervision on random walks through the state-space. This work is probably the closest to the proposed approach and it shows that Dyna can work with non-linear function approximators of the environment dynamics.
        
        The Dyna framework has neuroscientific grounding. It has been hypothesised that the parametric models of neocortex admit efficient inference but require long time to train. According to \cite{Kumaran2016}, this issue can be mitigated by hippocampus, which can quickly store experiences and either replay or simulate them during sleep. In this sense, simulations in Dyna are very similar to the experience-replay mechanism, which has been shown to stabilise and improve convergence of large-scale model-free RL models \citep{Mnih2015}.
        
        Dyna is not the only approach based on generative modelling. On the contrary, RL based on control in latent spaces has been quite successful. \cite{Watter2015} introduced Embed to Control (E2C), a stochastic locally-optimal control framework, which uses Variational Autoencoders (VAEs; \emph{cf.} \Cref{sec:unsupervised}) for learning of the latent-space for control. It approximates the latent-space dynamics by a locally-linear transition, which has controls as one of the inputs. The VAE manages to recover the true latent variables describing the state of the environment, which results in good long-term prediction performance. This type of long-term imagination could be used for multi-step roll-outs of model-based simulations in Dyna.  

%
%   Unsupervised & Self-supervised Learning
%   
    \subsection{Unsupervised Learning via Generative Modelling}
    \label{sec:unsupervised}
       While data in general are abundant and cheap, data for supervised learning are often expensive and time-consuming to gather. The majority of ML algorithms require relatively large amounts of labelled training data. \cite{Lake2016} suggest that machine learning typically starts without any prior knowledge of the world. This is in stark contrast to humans, who not only have a vast amount of knowledge about the world, but also expand it continuously and without any supervision \citep{Friston2009guide}. It is possible to learn without supervision by generative modelling of the probability distribution $\p{\bx} = \int \p{\bx, \bz} \dint \bz$ of observations $\bx$ in terms of some latent variables $\bz$. The latter \emph{explain} the former and can make the joint distribution $\p{\bx, \bz}$ tractable even in the case of an intractable marginal distribution. The latent encoding can be used in downstream tasks\eg for transfer or semi-supervised learning \citep{Pan2010}. \cite{Hinton2006dbn} introduced Deep Belief Networks (DBN) which explain the observations in terms of Bernoulli latent variables. Alternatively, we can introduce an approximate posterior distribution $\q{\bz}{}{\phi}$ parametrised by parameters $\phi$ and approximate the true data distribution by maximising the evidence lower bound (ELBO) $\loss[VAE]{\bx}$ on the log-probability of the data $\log \p{x} = \loss[VAE]{\bx} + \kl{ \q{\bz}{\bx}{\phi} }{ \p{\bz}{\bx} }$, where $\p{\bz}{\bx}$ is the true (intractable) posterior distribution. This approach results in variational autoencoders (VAE; \cite{Kingma2014,Rezende2014}). VAEs are much more flexible than DBNs as they allow latent variables from arbitrary probability distribution functions (pdf), can be trained end-to-end with off-the-shelf gradient-based methods and, in contrast to DBNs which require Markov Chain Mote Carlo sampling, admit efficient inference. Performance of VAEs depends on the choice of the approximate posterior distribution and a prior for the latent space. Since the latter is stochastic, the variance of the gradient estimator is increased compared to deterministic neural networks, which leads to slower convergence. These approaches are primarily suited to modelling datasets of independent and identically distributed (\emph{i.i.d.}) points.
       
       VAEs are especially interesting for the problem at hand because of their Bayesian nature: they are stochastic and they impose a prior on the latent space. ELBO can be written as $\loss[VAE]{\bx} = -\expc{ \p{\bx}{\bz}{\theta} }{}{\q{\bz} } + \kl{ \q{\bz} }{ \p{\bz} }$, where the second term is the KL-divergence between the approximate posterior and the prior. It can be interpreted as an encoding-length penalty that encourages minimum-coding length, but it also forces a \emph{particular} shape on the approximate posterior. It allows substituting samples from the prior for data, thereby creating new samples in the observation space, which is useful for creating model-based state-space roll-outs for Dyna.
%
%   Temporal dependencies in data; neural nets can learn dynamics and features from data
%
    \subsection{Sequence Modelling}
    \label{sec:seq_model}
    
        Traditional approaches to sequence modelling often consider inference of latent variables that explain the data\eg linear dynamical systems or hidden markov models \citep{Bishop2006}.
        They often require dynamics of the system to be known and often have too little capacity to model complex and high-dimensional real-world data.
        Neural networks, on the other hand, can learn both features and state dynamics from data and they can approximate functions of arbitrary complexity with arbitrary precision.
        Even early works on the topic demonstrated how useful neural networks are for prediction of chaotic time-series \citep{Lapedes1988}.
        Since then, neural networks have been successfully applied to sequence classification and prediction in different domains: written natural language, speech and audio, motion capture data or brain waves \citep{Langkvist2014,Bayer2015,Fortunato2017}.
%
%   Sequence Prediction as a type of unsupervised learning
%
        Sequence prediction is a promising method of unsupervised learning. The task is to predict the observation at time $t+1$ given a sequence of observations $\bxts$ up to time $t$. It is flexible in that it admits many different model types, including Gaussian processes, support vector machines or feed-forward neural networks, although models which can explicitly use temporal structure of data such as Gaussian process dynamic models (GPDM; \cite{Wang2008}) or recurrent neural networks (RNN) tend to perform better. Recently, sequential counterparts of VAEs have been proposed, which allow efficient generative modelling of sequences, with the additional advantage of better regularisation and superior uncertainty estimates \citep{Fabius2015,Bayer2015,Karl2017,Fortunato2017}. 
%        \ak{Mention encoding-length penalty, which encourages dropping unused latent variables} 
%        Unlike deterministic RNNs, sequential VAEs model time-series in terms of low-dimensional latent variables that can be used in downstream tasks. 
        Even though deterministic RNNs can be forced to learn low-dimensional representations by limiting the number of neurons in a layer, doing so can constrain learning and reduce performance. 
        In the initial stages of optimisation, neural models tend to explore all the available dimensions and only later converge to informative representations \citep{Shwartz-Ziv2017}.
        It is possible to encourage sparsity \citep{Engelcke2016} or compress the model \citep{Han2015}, but these approaches are based on heuristics. 
        Variational methods, on the other hand, ensure compact latent representations in a principled way by directly minimising the encoding length, see \Cref{sec:unsupervised}, but also \cite{Bishop2006} and \cite{Burda2015}. 
        Low-dimensional latent representation is important for our problem as difficulty of controlling an agent increases with increasing number of dimensions of the control space \citep{Watter2015}. While the control space is independent of the environment model, the latter should be conditioned on control inputs and controls can then be seen as controlling the evolution of the environment in the latent space.       
 
%%        
%%   State estimation & next-frame prediction     
%%      
%        The most relevant prior work is that on state estimation and next-frame prediction in videos. \cite{Ondruska2016} introduced Deep Tracking, which aims to estimate state in a partially-observable environment. 
%        It uses two-dimensional occupancy grids and predicts grid occupancy in the future. 
%        While related, it is unclear how this approach could be used to model any other type of data. 
%        Next-frame prediction has been done recently as predictive coding \citep{Lotter2016, Canziani2017}. 
%        The idea dates back to the Kalman filter \citep{Kalman1960} and states that the hidden state of the model should be updated only to remove any discrepancies between the predictions and the observations at the following time-steps. 
%        While very general, this approach imposes additional structure on the prediction problem: it 
%        (i) removes redundancies found in consecutive inputs, 
%        (ii) creates an inner feedback loop, which could adjust model dynamics at runtime to minimise any errors and 
%        (iii) could implement human-like attention mechanisms if realised probabilistically \citep{Friston2009guide}. 
    
  
    \subsection{Model Structure as Prior Information}
        As the majority of neural models are over-parametrised \citep{Denil2013}, learning abstract notions from data can be extremely sample inefficient. \cite{Eslami2016} introduced Attend, Infer, Repeat (AIR), a VAE with a variable-length latent encoding for image reconstruction. 
        This model imposes a geometric prior on the encoding length which encourages sparse solutions, therefore learning to decompose the scene into a number of independent parts --- the objects. 
        In the context of this report, a similar approach can determine parts of the scene that are relevant to an RL task; it also creates a separate latent representation for each object, thereby allowing explicit reasoning about single objects and relations between them.
        
        
%        It is worth noting that, along the main model, the authors introduce difference-AIR, which exploits the specific structure of the problem and adheres to the predictive coding paradigm, thereby achieving better performance. 
%        In the extension of this work, \cite{Rezende2016} learn to reconstruct three-dimensional (3D) structure of an object from even a single two-dimensional (2D) view by imposing 3D latent representation and structuring the decoder as a projection of the latent space into the 2D output space; they show that their model is able to infer the idea of an object from data.
%
%        \cite{Haeusser2017} learn the idea of an object and its class by learning to associate similar objects with each other in the embedding space, which is very much like a child learning about its identity by comparing itself with others \citep{Decety2003}.
%
%        In case of reinforcement learning, a complex environment might itself be a cue which leads to learning abstract ideas. \cite{Heess2017} show that articulated agents can learn real-world motion patterns by interacting with the environment. Specifically, they learn to crouch, jump, turn and run while maximising a very simple reward function based on forward progress.
%        \ak{why relevant?}
%   
        Using a specific model structure as a method of learning abstract ideas was also demonstrated by \cite{Battaglia2016}. The authors propose an interaction network, a highly complex model that operates on a graph of objects and relations between. Their application is to simulate physical systems under full observability, but additionally, the model structure enables learning invariants (\eg energy conservation) and inferring latent variables describing the system as a whole (\eg potential energy).
        Since we are interested in decomposing a scene into its parts and simulating the evolution of that scene, we can treat it as a physics system. Introducing structure that makes it easier to infer intuitive physics and system-level invariants can improve performance, especially when considering predictions under long temporal horizons.
        In the continuation of this work, \cite{Santoro2017} introduces \emph{relation networks} (RN). This simple component is permutation invariant and can process pairs of objects and infer relations between them. A major shortcoming of the approach is identifying objects. With our approach, however, explicit latent representation for every object is available by design; introducing RN as a component can be both helpful and simple.