\section{Research Proposal}
\label{sec:proposal}

%Things to write about:
%\begin{itemize}
%	\item Predictive Coding: next-frame prediction with VAEs, it's normalisation behaviour, inner feedback loop for corrections
%	\item Model-based RL: sample efficiency, using a policy to improve learning speed of the perception module, learn a policy in the absence of a goal
%	\item Unsupervised object tracking \& detection
%\end{itemize}

    Drawing from my experiences with HART, I am going to focus on representation learning for videos. I believe that imposing a specific model structure can lead to better, easier and faster learning and that generative modelling is able to produce neural representations that are easily transferable to other tasks. To this end, I would like to explore the predictive coding paradigm, or rather its instantiation within the variational inference framework. 
    Going further, I believe it is possible to combine attentive recurrent tracking with an approach similar to AIR \citep{Eslami2016} to create a generative model of a moving object, capable of inferring intuitive physics without any supervision.
    Finally, I would like to merge these two branches to learn a model of the environment and use it in a model-based reinforcement learning. In the following, I will describe the three ideas, explore connections between them and evaluate associated risks.
    
    
\subsection{Variational Inference for Predictive Coding}
\label{sec:pred}
   
   Predictive coding describes a family of models for sequence prediction. If a sequence predictor has a hidden state, one can argue that this state should be updated only in case of imperfect predictions, see \cref{sec:pred_coding} for details. \cite{Friston2009guide} argues that this type of sequence modelling is employed in the human brain, where it explains phenomena related to learning. He also represents the view that the brain is Bayesian and that any prediction in the human brain has to be probabilistic. In this case, the model can be optimised by minimising the information-theoretic surprise and the prediction error can be generalised to Mahalanobis distance \wrt the predictive probability distribution. This approach has not been explored in the machine learning literature, and yet it gives rise to a family of models shaped after the VAE, but reformulated for prediction as opposed to reconstruction of the input. This formulation has several advantages, including:
    \begin{description}
        \item[Non-stationary priors] A probabilistic prediction of the activations in the latent space can be used as a prior for the latent encoding at the next time-step. It maintains its properties as a regulariser while admitting higher flexibility of the approximate posterior distribution.
        
        \item[Self-normalisation] Probabilistic predictive coding can be used for normalisation of activations of neural networks. Given that we minimise surprise as the learning criterion, and assuming Gaussian output probability distribution, we can use the statistics of the distribution to whiten latent encoding at layer $l$ before inputting it to layer $l+1$. It can potentially alleviate or even solve the problem of covariance shift in the encoder part of the model, therefore removing any need for explicit normalisation (\eg batch normalisation). The validity of this argument is supported by the successful usage of neural baselines for variance reduction in score-function estimators \citep{Mnih2014}. It is unclear how normalisation of the encoder will impact learning of the whole system, nor whether it is possible to devise a similar method of normalising the decoder activations.
    \end{description}
    While not revolutionary in itself, the predictive coding paradigm imposes structure on the model and constrains the optimisation problem, potentially leading to faster and more sample-efficient learning.

\subsection{Unsupervised Learning to Track Objects}
\label{sec:obj}

    One can define an object in the image space as a patch of an image, where the correlation between pixels within the patch is strong, while the correlation between pixels inside and outside of the patch is weak. This definition, together with the penalty on the encoding length in the latent space, is in fact what makes AIR work. We can extend this definition to video sequences, where correlation between pixels in patches representing the same object at consecutive time-steps should be high under the assumption of high-enough frame rate. If video frames contain only simple objects on plain background, we can reformulate AIR for frame prediction instead of reconstruction to form a generative model of moving objects. This approach is unlikely to work with rich backgrounds or when an object constitutes only a small part of the scene, however. I believe that these issues can be addressed by background subtraction and soft visual attention, respectively. 
    
    \subsubsection{Background Subtraction}
    
        Assuming that the appearance of the object is known and is given by a vector $\bvt$, it is possible to segment it out of the image by using a dynamic filter network (DFN; \cite{Brabandere2016dfn}) in a very similar fashion to the dorsal stream of HART. Moreover, this segmentation model can be easily pre-trained (as proved by unpublished preliminary experiments) in an unsupervised way by cropping two overlapping patches from an image, treating one of them as the object and trying to find it within the second patch. If we assume that the initial tight bounding box is available (ground-truth, provided by an external object detector or AIR), we can easily extract the appearance vector.
    
    \subsubsection{Visual Attention}
        If the object is small relative to the image, background subtraction is unlikely to work due to the potentially large amount of noise in the segmentation. We can address this issue by using soft visual attention to crop the object or a small area around it from the image. This approach requires attention parameters, which can be initialised from the bounding box for the first frame or inferred from the sequence seen so far. 
  
    Given an attention glimpse $\bgt$ at time $t$ and an appearance vector $\bvt$, we can create an object mask $\bmt$ and compute a masked version of the glimpse $\bgt^m = \bmt \odot \bgt$, where $\odot$ denotes the Hadamard product. Given two masked glimpses at times $t$ and $t+1$, we can predict $\bg_{t+1}^m$ from $\bgt^m$ by using an AIR-like model.
    
    To drive learning, we can minimise the prediction loss of $\bg_{t+1}^m$ while maximising the area of the object mask $\bmt$ in the image space at the same time. The trade-off here is that $\bgt^m$ represents the appearance of the object and only the object, therefore it cannot be used to predict anything but the object at the next time-step; therefore minimising the prediction loss will also minimise the positive area of the object mask. Maximising the object mask area will prevent it from shrinking to zero. It will also, together with minimisation of the prediction loss, encourage accurate prediction of attention parameters, since if the attention glimpse does not contain the object it is virtually impossible to predict anything in or segment that glimpse.
    
    By combining all of the above, we arrive at a generative model of a moving object, which includes the motion model as well as the appearance model, both conditioned on the image background. Since the model is generative, we can condition it on a short video sequence and generate multiple trajectories in the image space by sampling from the prior; we can therefore examine the model for visual fidelity as well as physical plausibility of the generated paths. One caveat here is that the model will generate only the moving object, without its background. It might be necessary to use an additional component for background prediction, possibly conditioned on the predicted objects.
  
  

%    Let $\bxTs$ be an image sequence containing a moving object $o$ and let $\bm{b}_1$ be a bounding box around that object in the initial frame. Assuming that the bounding box is tight (\ie it contains the maximum amount of the object and the minimum amount of background possible) and assuming that the object appearance changes slower than the appearance of the object's background, it is possible to learn to track that object without any supervision. The learning framework to do so consists of the following steps:
%    \begin{enumerate}
%        \item extract an attention glimpse $\bgt$ containing the object $o$ in the image $\bxt$,
%        \item predict attention parameters and extract the attention glimpse $\bg_{t+1}$ at time $t+1$,
%        \item reconstruct $\bg_{t+1}$ from $\bgt$ using an approach similar to AIR. If the reconstruction is constrained to be rectangular and done in a single step, the reconstruction gives the bounding box coordinates $\bm{b}_{t+1}$ at time $t+1$.
%    \end{enumerate}
%    Beside the already mentioned assumptions, the above approach relies on the assumption that it is possible to predict attention parameters for the next time-step and that it is possible to reconstruct contents of a glimpse based on the contents of the glimpse at the previous time-step. Moreover, for the step (3) to work, that is, to have a bounding box as a result of reconstruction, we need to enforce that the object is contained within the glimpse. It is not immediately clear whether theses assumptions hold and it is one of the purposes of this project to determine their validity. We believe, however, that it is possible to enforce them and we will now describe how.
%    
%    
%    Given the initial tight bounding box and the initial frame, it should be clear that it is possible to reconstruct the object at the next time-step given its location. If we assume small object motions (high frame rate), we can assume that the object at time $t+1$ lies within the neighbourhood of the object at time $t$ and it is therefore enough to expand the size of the attention glimpse to cover the object at the next time step.  
%
%
%    Given that we know how the object looks like and given that we have a rough idea of where the object might be in the next frame, we can determine the object location in that frame: we can compute the object map (mechanism very similar to dorsal stream from HART).
%    
%    Once we have the object map, we can reconstruct not the whole glimpse, but only the parts of the glimpse indicated by the object mask as the part containing the object.
%    
%    Given that we can compute the object mask, we can learn the attention by maximising the positive area of the object mask (area containing the object), as this should encourage the attention to contain the object. There exists a degenerate solution, however. If the attention glimpse shrinks to a very small size, the object can easily cover the entire area of the glimpse. The solution would be to maximise not the size of the object within the glimpse, but the size of the object as indicated by the object mask but projected back to the image coordinates.
%    
%    This objective should be enough to learn to predict attention parameters.
%    
%    Reconstruction can be learned given object masks.
%    
%    It should be possible to learn object masks end-to-end with the other components of the system without encouraging them by any explicit loss function. The object mask should emerge from that fact that the background behind the object is relatively less correlated with the object itself, whereas the correlation between object appearance in subsequent frames is high. In case it proves to be impossible, it is possible to pretrain the object mask component without any supervision by...

\subsection{Model-based Reinforcement Learning}

    Predicting the next time-step in a structured manner might prove to be an effective way of representation learning. If a model learns intuitive physics directly from data, it can be useful model-based reinforcement learning. It remains to ask whether we can make the learning of the model faster, more general or more efficient by coupling it with an agent which can interact with its environment. Specifically, I would like to investigate the following:
    \begin{enumerate}
        \item Is it possible to use a policy for surprise-maximisation in a predictive coding setting? Can it lead to faster learning by exposing the model to otherwise rare events? 
        \item Can a surprise-minimisation policy be used in the absence of any explicit goal? How to avoid degenerate solutions in this case?
        \item Does predicting the next time-step lead to faster learning in RL, especially when rewards are sparse? Does it encourage or discourage exploration?
    \end{enumerate} 
    Approaches described in \cref{sec:obj,sec:pred} can be used for model learning in a model-based reinforcement learning setting. They can be used for pretraining or as unsupervised auxiliary tasks. While interactions between proposed methods and reinforcement learning remain unknown, they can potentially improve sample efficiency and scalability of reinforcement learning approaches and I am interested in exploring this topic.

